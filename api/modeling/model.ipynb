{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import RegexTokenizer, CountVectorizer, Word2Vec, Tokenizer\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes, LinearSVC, OneVsRest\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ah-ma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "customSchema = StructType([\n",
    "    StructField(\"label\", IntegerType()), \n",
    "    StructField(\"text\", StringType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = sqlContext.read.format(\"csv\").option(\"header\", \"true\").schema(customSchema).load('data/cleaned_twitter_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = sqlContext.read.format(\"csv\").option(\"header\", \"true\").schema(customSchema).load('data/cleaned_twitter_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"tokens\", pattern=r\" +\")\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "countVectors = CountVectorizer(inputCol=\"tokens\", outputCol=\"features\", vocabSize=15000, minDF=5)\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=0,maxIter=20, inputCol=\"tokens\", outputCol=\"features\")\n",
    "hashingTF = HashingTF(inputCol=\"tokens\", outputCol=\"rawFeatures\", numFeatures=15000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=10) #minDocFreq: remove sparse terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|                text|              tokens|            features|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|    3|getting borderlan...|[getting, borderl...|(13363,[67,77,154...|\n",
      "|    3|coming  borders  ...|[coming, borders,...|(13363,[266,304,6...|\n",
      "|    3|getting borderlan...|[getting, borderl...|(13363,[67,77,304...|\n",
      "|    3|coming borderland...|[coming, borderla...|(13363,[67,266,15...|\n",
      "|    3|getting  borderla...|[getting, borderl...|(13363,[67,77,154...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to training documents.\n",
    "pipeline = Pipeline(stages=[regexTokenizer, countVectors])\n",
    "pipelineFit = pipeline.fit(df_train)\n",
    "dataset_train = pipelineFit.transform(df_train)\n",
    "dataset_train.show(5)\n",
    "(trainingData, testData) = dataset_train.randomSplit([0.9, 0.1], seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|                text|              tokens|            features|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|    0|mentioned faceboo...|[mentioned, faceb...|(13363,[3,16,23,2...|\n",
      "|    2|bbc news amazon b...|[bbc, news, amazo...|(13363,[2,34,138,...|\n",
      "|    1|why pay  word  fu...|[why, pay, word, ...|(13363,[90,265,69...|\n",
      "|    1|csgo matchmaking ...|[csgo, matchmakin...|(13363,[0,115,262...|\n",
      "|    2|now  president sl...|[now, president, ...|(13363,[7,32,143,...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to validation documents.\n",
    "pipeline = Pipeline(stages=[regexTokenizer, countVectors])\n",
    "dataset_val = pipelineFit.transform(df_val)\n",
    "dataset_val.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10000, regParam=0.05, elasticNetParam=0.01, tol=1e-4, standardization=True)\n",
    "lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+-----+----------+\n",
      "|                          text|                   probability|label|prediction|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "| ban rule  battlefield play...|[0.9991763844793757,1.49322...|    0|       0.0|\n",
      "|loved  liverpool lost diogo...|[0.9970277626004036,2.45538...|    0|       0.0|\n",
      "|possible ban  battlefield p...|[0.9958923528770662,0.00134...|    0|       0.0|\n",
      "|join live  facebook today n...|[0.9953259770287342,5.16261...|    0|       0.0|\n",
      "|ban   battlefield might bas...|[0.9944248912442711,0.00144...|    0|       0.0|\n",
      "|why ali  best fortnite guy ...|[0.9938053261211168,3.96270...|    0|       0.0|\n",
      "|fifa liverpool worst night ...|[0.9925169070629243,0.00195...|    0|       0.0|\n",
      "|source ban claim  battlefie...|[0.9902175408746028,0.00603...|    0|       0.0|\n",
      "|ban  team battlefield secon...|[0.990191216260858,0.001199...|    0|       0.0|\n",
      "|sounds bit harsh  see print...|[0.9893114616429677,0.00435...|    0|       0.0|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8229204881510208"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lrModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0).select(\"text\",\"probability\",\"label\",\"prediction\")\\\n",
    ".orderBy(\"probability\", ascending=False).show(n = 10, truncate = 30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.write().overwrite().save(\"lr_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+-----+----------+\n",
      "|                          text|                   probability|label|prediction|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "|know the facts selected sel...|[0.9997861594389547,3.59986...|    1|       0.0|\n",
      "|why ali  best fortnite guy ...|[0.9995881400316241,2.21101...|    0|       0.0|\n",
      "|best barbie stream find sla...|[0.9993734150716964,5.13528...|    0|       0.0|\n",
      "| ban rule  battlefield play...|[0.9990398253296685,3.21265...|    0|       0.0|\n",
      "|really pleased   moves  tou...|[0.9988102769912741,1.63220...|    0|       0.0|\n",
      "|ban however  battlefield le...|[0.9985637107019326,4.39733...|    0|       0.0|\n",
      "|years ago princess pop bles...|[0.9979966598621328,5.33171...|    0|       0.0|\n",
      "|grifters outrage  moral dis...|[0.997681633414802,0.001794...|    0|       0.0|\n",
      "|this   great movie youunk f...|[0.997518051431198,8.501468...|    0|       0.0|\n",
      "|classic metal jewelry gift ...|[0.9961788663602594,9.91828...|    0|       0.0|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, hashingTF, idf])\n",
    "\n",
    "pipelineFit = pipeline.fit(df_train)\n",
    "dataset = pipelineFit.transform(df_train)\n",
    "\n",
    "(trainingData, testData) = dataset.randomSplit([0.9, 0.1], seed = 100)\n",
    "lr = LogisticRegression(maxIter=10000, regParam=0.05, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7432224930808944"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8372386654017403"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, countVectors])\n",
    "\n",
    "pipelineFit = pipeline.fit(df_train)\n",
    "dataset = pipelineFit.transform(df_train)\n",
    "(trainingData, testData) = dataset.randomSplit([0.9, 0.1], seed = 42)\n",
    "\n",
    "lr = LogisticRegression(maxIter=1000, regParam=0.05, elasticNetParam=0)\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "            #  .addGrid(lr.maxIter, [1000, 10000, 100000]) # number of iterations\n",
    "             .addGrid(lr.regParam, [0.01, 0.03, 0.05]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.0, 0.0]) # Elastic Net Parameter (Ridge = 0)\n",
    "             .build())\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel = cv.fit(trainingData)\n",
    "\n",
    "predictions = cvModel.transform(testData)\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit.save(\"saved-models/pipelineFit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel.write().overwrite().save('saved-models/cvModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|                text|              tokens|            features|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|    3|getting borderlan...|[getting, borderl...|(13364,[0,68,78,1...|\n",
      "|    3|coming  borders  ...|[coming, , border...|(13364,[0,267,305...|\n",
      "|    3|getting borderlan...|[getting, borderl...|(13364,[0,68,78,3...|\n",
      "|    3|coming borderland...|[coming, borderla...|(13364,[0,68,267,...|\n",
      "|    3|getting  borderla...|[getting, , borde...|(13364,[0,68,78,1...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to training documents.\n",
    "pipeline = Pipeline(stages=[tokenizer, countVectors])\n",
    "pipelineFit = pipeline.fit(df_train)\n",
    "dataset_train = pipelineFit.transform(df_train)\n",
    "dataset_train.show(5)\n",
    "(trainingData, testData) = dataset_train.randomSplit([0.9, 0.1], seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+-----+----------+\n",
      "|                          text|                   probability|label|prediction|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "|bitching  ghost tsushima  c...|[1.0,7.214055635348055E-17,...|    0|       0.0|\n",
      "|lockout  battlefield player...|[1.0,3.399544854284964E-17,...|    0|       0.0|\n",
      "|ban  battlefield player pin...|[1.0,1.1048417080972387E-17...|    0|       0.0|\n",
      "|the bigwigs    shopping mal...|[1.0,6.228762427389828E-18,...|    0|       0.0|\n",
      "|canya even find confirmatio...|[1.0,3.0500246515050898E-18...|    0|       0.0|\n",
      "|leaked  fifa fifa gta gamep...|[1.0,9.41337092315493E-19,3...|    0|       0.0|\n",
      "|unfortunately though cannot...|[1.0,6.33331275006352E-19,1...|    0|       0.0|\n",
      "|source ban claim  battlefie...|[1.0,5.9864963635378215E-19...|    0|       0.0|\n",
      "|accelerate  war drugs paral...|[1.0,5.272570825134445E-20,...|    0|       0.0|\n",
      "|this   great movie youunk f...|[1.0,5.7013459846858816E-21...|    0|       0.0|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7617420005786116"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = NaiveBayes(modelType='multinomial', smoothing=1e-4)\n",
    "nbModel = nb.fit(trainingData)\n",
    "\n",
    "predictions = nbModel.transform(testData)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0).select(\"text\",\"probability\",\"label\",\"prediction\")\\\n",
    ".orderBy(\"probability\", ascending=False).show(n = 10, truncate = 30)\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|                text|              tokens|         rawFeatures|            features|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|    3|getting borderlan...|[getting, borderl...|(15000,[3031,3372...|(15000,[3031,3372...|\n",
      "|    3|coming  borders  ...|[coming, , border...|(15000,[201,3372,...|(15000,[201,3372,...|\n",
      "|    3|getting borderlan...|[getting, borderl...|(15000,[3372,6586...|(15000,[3372,6586...|\n",
      "|    3|coming borderland...|[coming, borderla...|(15000,[3031,3372...|(15000,[3031,3372...|\n",
      "|    3|getting  borderla...|[getting, , borde...|(15000,[3031,3372...|(15000,[3031,3372...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to training documents.\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf])\n",
    "pipelineFit = pipeline.fit(df_train)\n",
    "dataset_train = pipelineFit.transform(df_train)\n",
    "dataset_train.show(5)\n",
    "(trainingData, testData) = dataset_train.randomSplit([0.9, 0.1], seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC(maxIter=10000, regParam=0.05, tol=1e-7, standardization=True)\n",
    "ovr = OneVsRest(classifier=svc)\n",
    "ovrModel = ovr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----+----------+\n",
      "|                          text|label|prediction|\n",
      "+------------------------------+-----+----------+\n",
      "|mentioned facebook   strugg...|    0|       0.0|\n",
      "|call duty warzone livestrea...|    0|       0.0|\n",
      "|                best squad yet|    0|       0.0|\n",
      "|this really disappointing m...|    0|       0.0|\n",
      "|              melusi   shocked|    2|       0.0|\n",
      "|      blocking  mans new level|    0|       0.0|\n",
      "|everyone know  story true l...|    0|       0.0|\n",
      "|sound enjoy  groove   littl...|    0|       0.0|\n",
      "|aoc  make   ignorant commen...|    0|       0.0|\n",
      "|nyummm delicious finally so...|    0|       0.0|\n",
      "+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8925784039743436"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = ovrModel.transform(dataset_val)\n",
    "predictions.filter(predictions['prediction'] == 0).select(\"text\",\"label\",\"prediction\")\\\n",
    ".show(n = 10, truncate = 30)\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
